{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from pyphm.datasets.ims import ImsDataLoad\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tim/Documents/PyPHM\n",
      "/home/tim/Documents/PyPHM/data\n"
     ]
    }
   ],
   "source": [
    "root_dir = Path.cwd().parent\n",
    "print(root_dir)\n",
    "path_data_raw_folder = Path(root_dir / 'data' )\n",
    "print(path_data_raw_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = ImsDataLoad(path_data_raw_folder, 'ims', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1st_folder = ims.path_1st_folder\n",
    "path_2nd_folder = ims.path_2nd_folder\n",
    "path_3rd_folder = ims.path_3rd_folder\n",
    "\n",
    "file_list = sorted(os.listdir(path_2nd_folder))\n",
    "file_name = file_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_csv(file_info_dict) -> None:\n",
    "    \"\"\"Load an individual sample (.csv file) of the IMS data set.\"\"\"\n",
    "\n",
    "    path_run_folder = file_info_dict[\"path_run_folder\"]\n",
    "    file_name = file_info_dict[\"file_name\"]\n",
    "    sample_freq = file_info_dict[\"sample_freq\"]\n",
    "    col_names = file_info_dict[\"col_names\"]\n",
    "    run_no = file_info_dict[\"run_no\"]\n",
    "    sample_index = file_info_dict[\"sample_index\"]\n",
    "\n",
    "    # load the .csv file\n",
    "    signals_array = np.loadtxt(path_run_folder / file_name, delimiter=\"\\t\")\n",
    "\n",
    "    id_list = [f\"{run_no}_{sample_index}\"] * len(signals_array)\n",
    "    run_list = [run_no] * len(signals_array)\n",
    "    file_list = [file_name] * len(signals_array)\n",
    "    time_step_array = np.linspace(\n",
    "        0.0, len(signals_array) / sample_freq, len(signals_array)\n",
    "    )\n",
    "\n",
    "    # create dictionary with the signals_array, id_list, run_list, file_list, time_step_array\n",
    "    data_dict = {\n",
    "        \"signals_array\": signals_array,\n",
    "        \"id_list\": id_list,\n",
    "        \"run_list\": run_list,\n",
    "        \"file_list\": file_list,\n",
    "        \"time_step_array\": time_step_array,\n",
    "    }\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_run_folder = ims.path_2nd_folder\n",
    "col_names = ims.col_2nd_names\n",
    "\n",
    "\n",
    "# create a list of dictionaries containing the metadata for each file\n",
    "file_info_list = []\n",
    "for i, file_name in enumerate(sorted(os.listdir(path_run_folder))):\n",
    "    file_info_list.append(\n",
    "        {\n",
    "            \"path_run_folder\": path_run_folder,\n",
    "            \"file_name\": file_name,\n",
    "            \"sample_freq\": 20480.0,\n",
    "            \"col_names\": col_names,\n",
    "            \"run_no\": 1,\n",
    "            \"sample_index\": i,\n",
    "        }\n",
    "    )\n",
    "\n",
    "with mp.Pool(processes=6) as pool:\n",
    "\n",
    "    # from https://stackoverflow.com/a/36590187\n",
    "    data_list = pool.map(process_raw_csv, file_info_list)\n",
    "\n",
    "# store the data from data_list as a dictionary, with the key being the file name\n",
    "data_dict = {}\n",
    "for data_dict_i in data_list:\n",
    "    data_dict[data_dict_i['file_list'][0]] = data_dict_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2004.02.12.10.32.39'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = list(data_dict.keys())[0]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20480, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[d]['signals_array'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy_arrays(data_dict):\n",
    "\n",
    "    # create a list to store the x and y arrays\n",
    "    x = []  # instantiate X's\n",
    "    y_ids_runs_files_times = []  # instantiate y's\n",
    "\n",
    "    # get all the file names from the data_dict and sort them\n",
    "    file_names = sorted(data_dict.keys())\n",
    "\n",
    "    # iterate through the file names and append the x and y arrays\n",
    "    # \"id_list\"        \"signals_array\": signals_array,\n",
    "    # data_dict = {\n",
    "    #     \"signals_array\": signals_array,\n",
    "    #     \"id_list\": id_list,\n",
    "    #     \"run_list\": run_list,\n",
    "    #     \"file_list\": file_list,\n",
    "    #     \"time_step_array\": time_step_array,\n",
    "    # }\n",
    "    for file_name in file_names:\n",
    "        x.append(data_dict[file_name]['signals_array'])\n",
    "        y_ids_runs_files_times.append(\n",
    "            [\n",
    "                data_dict[file_name]['id_list'],\n",
    "                data_dict[file_name]['run_list'],\n",
    "                data_dict[file_name]['file_list'],\n",
    "                data_dict[file_name]['time_step_array'],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    x = np.stack(x)\n",
    "    n_samples = x.shape[0]\n",
    "    n_signals = x.shape[2]\n",
    "\n",
    "    return x, np.stack(y_ids_runs_files_times).reshape(n_samples, -1, n_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20480\n",
      "984\n"
     ]
    }
   ],
   "source": [
    "x, y_ids_runs_files_times = create_xy_arrays(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 20480, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 20480, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ids_runs_files_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "for signals_dict in data_list:\n",
    "    data_dict[signals_dict['file_list'][0]] = signals_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_run_as_df(\n",
    "    run_no: int,\n",
    "    n_jobs: int = None,\n",
    ") -> None:\n",
    "    \"\"\"Load the three runs as individual dataframes.\"\"\"\n",
    "\n",
    "    if run_no == 1:\n",
    "        col_names = self.col_1st_names\n",
    "        path_run_folder = self.path_1st_folder\n",
    "    elif run_no == 2:\n",
    "        col_names = self.col_2nd_names\n",
    "        path_run_folder = self.path_2nd_folder\n",
    "    else:\n",
    "        col_names = self.col_3rd_names\n",
    "        path_run_folder = self.path_3rd_folder\n",
    "\n",
    "    # get list of every file in the folder and sort by ascending date\n",
    "    file_list = sorted(os.listdir(path_run_folder))\n",
    "\n",
    "    # create a list of dictionaries containing the metadata for each file\n",
    "    file_info_list = []\n",
    "    for i, file_name in enumerate(sorted(os.listdir(path_run_folder))):\n",
    "        file_info_list.append(\n",
    "            {\n",
    "                \"path_run_folder\": path_run_folder,\n",
    "                \"file_name\": file_name,\n",
    "                \"sample_freq\": 20480.0,\n",
    "                \"col_names\": col_names,\n",
    "                \"run_no\": run_no,\n",
    "                \"sample_index\": i,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # get number of cpu cores\n",
    "    if n_jobs is None:\n",
    "        n_jobs = mp.cpu_count() - 2\n",
    "    if n_jobs < 1:\n",
    "        n_jobs = 1\n",
    "\n",
    "    # load the dataframes in parallel\n",
    "    with mp.Pool(processes=n_jobs) as pool:\n",
    "\n",
    "        # from https://stackoverflow.com/a/36590187\n",
    "        df_run = pool.map(self.process_raw_csv, file_info_list)\n",
    "        df = pd.concat(df_run, ignore_index=True)\n",
    "\n",
    "    col_names_ordered = [\"id\", \"run\", \"file\", \"time_step\"] + col_names\n",
    "\n",
    "    return df[col_names_ordered]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "daff1afd4d675d5e247c0a95a5de0c03bd87d8f7edee7cb37c539016070f1c16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('featstore': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
